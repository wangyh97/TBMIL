{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3ba95332-1e25-4eb4-8189-361e0aedbd33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-26T14:51:37.486742Z",
     "start_time": "2024-01-26T14:51:37.466834Z"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaa08d4-fa4b-4581-8ddb-7603cecb87f2",
   "metadata": {},
   "source": [
    "# function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9379d6c0-b2c8-41b3-8a32-7f9824938393",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T13:26:27.065580Z",
     "start_time": "2024-01-27T13:26:27.036289Z"
    }
   },
   "outputs": [],
   "source": [
    "def grid_args_generator(lr_range_ls,wd_range_ls,steps:str=False,steps_lr=10,steps_wd=10,mode:str='linspace'):\n",
    "    '''\n",
    "    description: grid search function\n",
    "    args:\n",
    "        lr_range_ls:list of tuples, every tuple is constructed in form of (lr_start,lr_end)\n",
    "        wd_range_ls:list of tuples, in form that is similar to lr_range_ls\n",
    "        steps: steps in linspace/logspace when generating seq of lr/wd,if assigned, steps_lr & steps_wd will be assigned the same as steps\n",
    "    '''\n",
    "    lr_ls = []\n",
    "    wd_ls = []\n",
    "    if steps:\n",
    "        steps_lr = eval(steps)\n",
    "        steps_wd = eval(steps)\n",
    "    assert mode in ['linspace','logspace'], 'wrong space searching strategy,should be choosen from [linspace,logspace]'\n",
    "    if mode == 'linspace':\n",
    "        f = np.linspace\n",
    "    if mode == 'logspace':\n",
    "        f = np.logspace\n",
    "    for lr_range in lr_range_ls:\n",
    "        lr_ls += f(lr_range[0],lr_range[1],steps_lr,endpoint=False).tolist()\n",
    "        \n",
    "    if type(wd_range_ls) != list: #若固定wd，wd_range_ls为一固定数值\n",
    "        wd_ls = [wd_range_ls]\n",
    "    else:\n",
    "        for wd_range in wd_range_ls:\n",
    "            wd_ls += f(wd_range[0],wd_range[1],steps_wd,endpoint=False).tolist()\n",
    "\n",
    "    hyperparameter_combs = [i for i in product(lr_ls,wd_ls)]\n",
    "    return hyperparameter_combs\n",
    "\n",
    "def random_args_generator(lr_range_ls, wd_range_ls, num_lr, num_wd, **kwargs):\n",
    "    \"\"\"\n",
    "    description: random search function.\n",
    "\n",
    "    Args:\n",
    "        lr_range_ls (list): List of learning rate ranges, each element is a tuple (min, max)\n",
    "        wd_range_ls (list): List of weight decay ranges, each element is a tuple (min, max)\n",
    "        num_trials (int): Number of random trials\n",
    "\n",
    "    Returns:\n",
    "        list: A list of randomly sampled hyperparameter combinations (lr, wd)\n",
    "    \"\"\"\n",
    "    random.seed(42)\n",
    "    lr_ls = []\n",
    "    wd_ls = []\n",
    "\n",
    "    for lr_range in lr_range_ls:\n",
    "        lr_min, lr_max = lr_range\n",
    "        lr_ls += [random.uniform(lr_min, lr_max) for _ in range(num_lr)]\n",
    "\n",
    "    for wd_range in wd_range_ls:\n",
    "        wd_min, wd_max = wd_range\n",
    "        wd_ls += [random.uniform(wd_min, wd_max) for _ in range(num_wd)]\n",
    "    \n",
    "    if kwargs:\n",
    "        print('kwargs passed')\n",
    "        hyperparameter_combs = [i for i in product(lr_ls,wd_ls,kwargs['dropout_patch'],kwargs['dropout_node'])]\n",
    "    else:\n",
    "        print('kwargs not passed')\n",
    "        hyperparameter_combs = [i for i in product(lr_ls,wd_ls)]\n",
    "    \n",
    "    return hyperparameter_combs\n",
    "    \n",
    "def bash_file_generator(hyperparameter_combs,description,k=5,extractor='pretrained_resnet18',scale=10,feats_size=512,average=True,num_classes = 2,num_epoch=75,total_gpu=4,gpu_count=4,record='best',reg=False,reg_coef=0,warmup=False):\n",
    "    '''\n",
    "    same as above, use train_PtRes which read from pretrained Resnet18 extracted feature，with complete API\n",
    "    update:\n",
    "        folding out_files & sh files of one batch:\n",
    "            out_file_saving_dir: /out/5_classifier/hyperparam_select_batch{run}\n",
    "            sh_file_saving_dir: /processing/mil classifier/hyperparam_select_batch_{run}\n",
    "        self_detecting if the saving files exists,makedir if not\n",
    "        \n",
    "    2023-5-14 update:\n",
    "        Notice:!!!\n",
    "        add arg:layer, 18 by default --- control a print info below & train_PtRes{layer}.py selection\n",
    "            ***for PtRes18 features, train file is named as train_PtRes without layer info***\n",
    "            ***newly formed sh file using batch3-6 function will not run correctly , train_PtRes.py need to be renamed as train_PtRes18.py***\n",
    "    2023-5-15 update:\n",
    "        add arg record = False\n",
    "    2023-6-23 update:\n",
    "        change arg record[str]: select from ['none','best','all']\n",
    "        remove arg run, use arg description[str] instead:\n",
    "            brief description of the trial, used as daughter folder name under folder <5-classifier>\n",
    "        set Tmax as 100\n",
    "    '''\n",
    "    string = {}\n",
    "    count = 1\n",
    "    N = len(hyperparameter_combs)\n",
    "    print(f'{N} hypermarameter combinations in total,run with {extractor} extracted features')\n",
    "    for i in range(total_gpu):\n",
    "        string[f'block{i+1}'] = ''\n",
    "        \n",
    "    #path detection    \n",
    "    out_saving_dir = f'./train/training_outfiles/{description}'\n",
    "    if not os.path.exists(out_saving_dir):\n",
    "        os.makedirs(out_saving_dir) \n",
    "    sh_saving_dir = f'./train/training_details/{description}'\n",
    "    if not os.path.exists(sh_saving_dir):\n",
    "        os.makedirs(sh_saving_dir)\n",
    "        \n",
    "    for id,i in enumerate(hyperparameter_combs):\n",
    "        if len(i) == 2:\n",
    "            dropout_node=0\n",
    "            dropout_patch=0\n",
    "            string[f'block{count}'] += f'nohup python ../../train.py --description {description} --lr {i[0]} --weight_decay {i[1]} --Tmax {num_epoch} --extractor {extractor} --kfold {k} --scale {scale} --feats_size {feats_size} --average {average} --dropout_node {dropout_node} --dropout_patch {dropout_patch} --num_epochs {num_epoch} --num_classes {num_classes} --gpu_index {count%gpu_count} --record {record} --reg {reg} --reg_coef {reg_coef} --warmup {warmup}> ../../training_outfiles/{description}/train_tcga_{id}.out \\n'\n",
    "        elif len(i) == 4:\n",
    "            string[f'block{count}'] += f'nohup python ../../train.py --description {description} --lr {i[0]} --weight_decay {i[1]} --Tmax {num_epoch} --extractor {extractor} --kfold {k} --scale {scale} --feats_size {feats_size} --average {average} --dropout_node {i[2]} --dropout_patch {i[3]} --num_epochs {num_epoch} --num_classes {num_classes} --gpu_index {count%gpu_count} --record {record} --reg {reg} --reg_coef {reg_coef} --warmup {warmup}> ../../training_outfiles/{description}/train_tcga_{id}.out \\n'\n",
    "        if (id+1)%(N//total_gpu+1) == 0:\n",
    "            count +=1\n",
    "    for i in range(total_gpu):\n",
    "        with open(f'{sh_saving_dir}/{description}_{i+1}.sh','w') as f:\n",
    "            f.write(string[f'block{i+1}'])\n",
    "    print('file generated')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa741d1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T14:47:32.191675Z",
     "start_time": "2023-07-25T14:47:32.189458Z"
    }
   },
   "source": [
    "# 2024-1-25 train，新提取的patch（threshold = 100）,random search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e5bf34-4b8c-4851-a811-346cc0f3b624",
   "metadata": {},
   "source": [
    "## 10X, fold5\n",
    "### pretrained resnet18，pretrained resnet50，ctranspath，retccl，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8524ad24-647b-4480-a817-d6fc4ee1ecf6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-28T03:04:08.095298Z",
     "start_time": "2024-01-28T03:04:07.336620Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs not passed\n",
      "81 hypermarameter combinations in total,run with retccl_resnet50_2048 extracted features\n",
      "file generated\n",
      "81 hypermarameter combinations in total,run with retccl_resnet50_2048 extracted features\n",
      "file generated\n",
      "81 hypermarameter combinations in total,run with pretrained_resnet18 extracted features\n",
      "file generated\n",
      "81 hypermarameter combinations in total,run with pretrained_resnet18 extracted features\n",
      "file generated\n",
      "81 hypermarameter combinations in total,run with pretrained_resnet50 extracted features\n",
      "file generated\n",
      "81 hypermarameter combinations in total,run with pretrained_resnet50 extracted features\n",
      "file generated\n",
      "81 hypermarameter combinations in total,run with cTransPath extracted features\n",
      "file generated\n",
      "81 hypermarameter combinations in total,run with cTransPath extracted features\n",
      "file generated\n",
      "81 hypermarameter combinations in total,run with TCGA_high extracted features\n",
      "file generated\n",
      "81 hypermarameter combinations in total,run with TCGA_high extracted features\n",
      "file generated\n",
      "81 hypermarameter combinations in total,run with TCGA_low extracted features\n",
      "file generated\n",
      "81 hypermarameter combinations in total,run with TCGA_low extracted features\n",
      "file generated\n",
      "81 hypermarameter combinations in total,run with c16_high extracted features\n",
      "file generated\n",
      "81 hypermarameter combinations in total,run with c16_high extracted features\n",
      "file generated\n"
     ]
    }
   ],
   "source": [
    "def batch1():\n",
    "    lr_range_ls = [(1e-4,1e-3),(1e-5,1e-4),(1e-6,1e-5)]\n",
    "    wd_range_ls = [(1e-5,1e-4),(1e-4,1e-3),(1e-6,1e-5)]\n",
    "    hyperparameter_combs = random_args_generator(lr_range_ls,wd_range_ls,num_lr=3,num_wd=3)\n",
    "    bash_file_generator(hyperparameter_combs,description='10X_5fold_retccl',k=5,scale=10,extractor='retccl_resnet50_2048',num_epoch=75,record='best',feats_size=2048,total_gpu=4,gpu_count=4,num_classes=1)\n",
    "    bash_file_generator(hyperparameter_combs,description='20X_5fold_retccl',k=5,scale=20,extractor='retccl_resnet50_2048',num_epoch=75,record='best',feats_size=2048,total_gpu=4,gpu_count=4,num_classes=1)\n",
    "    bash_file_generator(hyperparameter_combs,description='10X_5fold_pretrained_resnet18',k=5,scale=10,extractor='pretrained_resnet18',num_epoch=75,record='best',total_gpu=4,gpu_count=4,num_classes=1)\n",
    "    bash_file_generator(hyperparameter_combs,description='20X_5fold_pretrained_resnet18',k=5,scale=20,extractor='pretrained_resnet18',num_epoch=75,record='best',total_gpu=4,gpu_count=4,num_classes=1)\n",
    "    bash_file_generator(hyperparameter_combs,description='10X_5fold_pretrained_resnet50',k=5,scale=10,extractor='pretrained_resnet50',num_epoch=75,record='best',total_gpu=4,gpu_count=4,num_classes=1)\n",
    "    bash_file_generator(hyperparameter_combs,description='20X_5fold_pretrained_resnet50',k=5,scale=20,extractor='pretrained_resnet50',num_epoch=75,record='best',total_gpu=4,gpu_count=4,num_classes=1)\n",
    "    bash_file_generator(hyperparameter_combs,description='10X_5fold_cTransPath',k=5,scale=10,extractor='cTransPath',num_epoch=75,record='best',feats_size=768,total_gpu=4,gpu_count=4,num_classes=1)\n",
    "    bash_file_generator(hyperparameter_combs,description='20X_5fold_cTransPath',k=5,scale=20,extractor='cTransPath',num_epoch=75,record='best',feats_size=768,total_gpu=4,gpu_count=4,num_classes=1)\n",
    "    bash_file_generator(hyperparameter_combs,description='10X_5fold_TCGA_high',k=5,scale=10,extractor='TCGA_high',num_epoch=75,record='best',feats_size=256,total_gpu=4,gpu_count=4,num_classes=1)\n",
    "    bash_file_generator(hyperparameter_combs,description='20X_5fold_TCGA_high',k=5,scale=20,extractor='TCGA_high',num_epoch=75,record='best',feats_size=256,total_gpu=4,gpu_count=4,num_classes=1)\n",
    "    bash_file_generator(hyperparameter_combs,description='10X_5fold_TCGA_low',k=5,scale=10,extractor='TCGA_low',num_epoch=75,record='best',feats_size=256,total_gpu=4,gpu_count=4,num_classes=1)\n",
    "    bash_file_generator(hyperparameter_combs,description='20X_5fold_TCGA_low',k=5,scale=20,extractor='TCGA_low',num_epoch=75,record='best',feats_size=256,total_gpu=4,gpu_count=4,num_classes=1)\n",
    "    bash_file_generator(hyperparameter_combs,description='10X_5fold_c16_high',k=5,scale=10,extractor='c16_high',num_epoch=75,record='best',feats_size=256,total_gpu=4,gpu_count=4,num_classes=1)\n",
    "    bash_file_generator(hyperparameter_combs,description='20X_5fold_c16_high',k=5,scale=20,extractor='c16_high',num_epoch=75,record='best',feats_size=256,total_gpu=4,gpu_count=4,num_classes=1)\n",
    "batch1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd87ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-ds]",
   "language": "python",
   "name": "conda-env-.conda-ds-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
